---
layout: post
title: Insteresting Image Styles and Neural Networks
images:
  - url: /images/smirror/pic4.jpg
---

<!DOCTYPE html>
<html>

<head>
	<style type="text/css">
		body {
		    font: normal 20px Verdana, Arial, sans-serif;
		}

		pre code {
		  background-color: #eee;
		  border: 1px solid #999;
		  display: block;
		  padding: 20px;
      overflow-x:scroll;
		}
	</style>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/languages/go.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

</head>
<body>

<!-- <img src="/images/smirror/pic4.jpg">  <br/>
 -->

<p>
Neural Network, is still growing in a pretty high speed, has been put in many applications in especially computer vision area, Image Style Transfer is a really interesting one among those applications. Imagine you hired a painter to draw something in some specific styles such as Impressionism, but in this case, the “style” would be more specific to one image.
</p>
<br/>
<img src="/images/styletrans/example1.jpeg"><br/>

<p>
 According to the paper Image Style Transfer Using Convolutional Neural Networks(http://openaccess.thecvf.com/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf), when we apply the convolutional neural network to some functions such as object recognition, a representation of the object will be generated to “make the image information increasingly explicit along processing hierarchy”(3). When we are trying to transfer the style of a painting to, let’s say, a photograph, we get content representations of both images and, at the same time, generate a new image (a white noise image), making this new image match the representations of those two images more and more. 
</p>

<h3>Stucture:</h3>
<p>
The whole loss consists of three parts: content loss, style loss and the total loss, the relationships of these three parts and how they are gonna work together can be depicted in the figure below:
</p>
<img src="/images/styletrans/structure.jpg"><br/>
<p>
From <a href="https://medium.com/mlreview/making-ai-art-with-style-transfer-using-keras-8bb5fa44b216">Walid Ahmad’s blog </a>  about Style Transfer using Keras, the all the equations are interpreted pretty well. 
</p>

Content Loss:<br/>
<img src="/images/styletrans/contentloss.png"><br/>
<br/>

Gram Matrix:<br/>
<img src="/images/styletrans/grammatrix.png"><br/>
<br/>

Style Loss:<br/>
<img src="/images/styletrans/styleloss.png"><br/>
<img src="/images/styletrans/styleloss2.png"><br/>
<br/>

Total Loss:<br/>
<img src="/images/styletrans/tloss.png"><br/>

<h1>Networks</h1>
<p>
There are quite a few options for Pre-trained Neural Network, here I am going to talk about some of them.
</p>

<h5>VGG 16</h5>
<p>
VGG 16 is the most popular neural network to extract features of images in style transfering, the VGG 16, with totally 19 layers, mostly consists of 3*3 convolutional layers and maxpooling layers, with deeper and smaller filters and fewer parameters through each filter, it has more non-linearities
</p>
<img src="/images/styletrans/vgg.jpeg"><br/>
<p>
There are also many resources about style transfer implemented with VGG16, the 19 layers are divided into 5 blocks, to calculate the content loss, people usually pick the output of some convolutional layer in block 4 as the layer they get the features to plug into the equation, for style loss, usually the output of the first convolutional layer in each block is picked to form the style layer set. But it's not necessarily the only way to pick it, the results would vary based on what layers we pick for the loss calculation.
</p>

<h5>SqueezeNet</h5>
<p>
SqueezeNet is another excellent architecture of neural network with very small size trained on ImageNet. Nowadays, SqueezeNet has made a huge impact with its unique convenience and power. 
</p>
<img src="/images/styletrans/squeeze.jpeg"><br/>
<p>
The SqueezeNet uses 1*1 convolutional layers instead of 3*3 so that its size is much smaller and less computation is involved while the feature map is respectively bigger. 

If you have done the Style Transfer assignment of Stanford CS231n, you probably remember the SqueezeNet was used in that assignment due to its efficiency. 
</p>


<h5>Results</h5>
<p>
If it works well, you will see something like the image below, this was experiemented with SqueezeNet.
</p>
<img src="/images/styletrans/example2.jpg"><br/>

<p>
By changes style image weights for the style layer set and content image weight, you can see some difference like below:
</p>
<img src="/images/styletrans/example3.jpg"><br/>
<img src="/images/styletrans/example4.jpg"><br/>

<p>
But this technique is only limited for overall effect of the whole image, instead of some specified features.
</p>
<img src="/images/styletrans/example5.jpg"><br/>
<p>
Obviously, this didn't work... Looks like the computer knows there is no way that a combination of such two perfect faces exists.
</p>


<h3>Suggested Reading:</h3>

Reference:<br/>
1. <a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf">Image Style Transfer Using Convolutional Neural Networkse</a><br/>

2. <a href="https://www.cs.cornell.edu/~fujun/files/style-cvpr17/style-cvpr17.pdf">Deep Photo Style Transfer</a><br/>

3. <a href="https://medium.com/mlreview/making-ai-art-with-style-transfer-using-keras-8bb5fa44b216">Making AI Art with Style Transfer using Keras</a>
<br/>
<br/>
Suggested Reading:<br/>
<a href="https://harishnarayanan.org/writing/artistic-style-transfer/">Convolutional neural networks for artistic style transfer</a><br/>

<a href="https://arxiv.org/pdf/1602.07360v3.pdf">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 0.5MB model size </a><br/>

<a href="https://towardsdatascience.com/artistic-style-transfer-b7566a216431">Artistic Style Transfer</a>

</body>
</html>

